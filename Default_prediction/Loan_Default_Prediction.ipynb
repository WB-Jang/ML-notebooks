{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpQbXVu9F/q7wU/nHuuYWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WB-Jang/ML-notebooks/blob/main/Default_prediction/Loan_Default_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 은행 여신 계좌의 Default를 예측하기 위한 Deep Learning Development\n",
        "(1) Data Set\n",
        "- FY 2024 all seg loan acct\n",
        "- Each month-end snapshot\n",
        "- All columns are divided into 2 group : Numerical, Categorical\n",
        "-\n",
        "- Only from 68 columns  \n",
        "## Pre-training\n",
        "- Masked Auto-Encoder ver\n",
        "- Contrastive Learning ver"
      ],
      "metadata": {
        "id": "o6N9t31rbzxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuarcy_score, roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    # Transformer Encdoer\n",
        "    def __init__(self, cnt_cat_features, cnt_num_features, cat_max_dict, d_model=32, nhead=4, num_layers=6, dim_feedforward=64, dropout_rate=0.3):\n",
        "      super().__init__()\n",
        "      self.d_model = d_model\n",
        "      self.cnt_cat_features = cnt_cat_features\n",
        "      self.cnt_num_features = cnt_num_features\n",
        "    # 범주형 변수 임베딩\n",
        "      \"\"\"\n",
        "      nn.Embedding은 하나의 Lookup table과 같아서, 첫 번째 인자만큼의 행에 두 번째 인자 길이만큼의 차원을 가진 벡터를 각각 생성함.\n",
        "      예를 들어, nn.Embedding(78,32)라면, 0~77에 해당하는 32차원의 고유한 벡터를 생성하고, 0이 들어오면 첫 번째 행의 32차원 벡터를 출력하고, 7이 들어오면 7번째 행의 32차원 벡터를 출력\n",
        "      \"\"\"\n",
        "      self.embeddings = nn.ModuleList([\n",
        "          nn.Embedding(cat_max_dict[i],d_model) for i in range(cnt_cat_features)\n",
        "\n",
        "      ])\n",
        "    # 수치형 변수 임베딩 : 수치는 실수 크기의 정보를 담은 vector로 변환해야 하므로 nn.Linear를 사용해야 한다\n",
        "      self.num_embeddings = nn.ModuleList([\n",
        "          nn.Linear(1,d_model) for _ in range(cnt_num_features)\n",
        "      ])\n",
        "\n",
        "    # Transformer 인코더 레이어 정의\n",
        "      encoder_layer = nn.TransformerEncoderLayer( # TransformerEncoderLayer에는 self-attention이 기본으로 포함. CrossAttention이 필요하다면, nn.TransformerDecoderLayer 사용\n",
        "          d_model=d_model\n",
        "          , nhead=nhead\n",
        "          , dim_feedforward=dim_feedforward\n",
        "          , dropout=dropout_rate\n",
        "          , batch_first=True # batch_first 옵션은 입력 차원을 (Sequential_length, batch_size, embedding_dim) -> (batch_size, Sequential_length, embedding_dim)로 변경. 이렇게 변경하면 각 data point 별로 하나의 tabular data 형식을 가짐\n",
        "          , norm_first=True # norm_first 옵션은 layer_norm -> residual_connection 순서로 진행한다는 의미. 직관적으로 생각했을 때에는, Residual Connection -> Layer norm을 하게 되면, Residual의 의미가 반감되는 느낌.\n",
        "      )\n",
        "      self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        "      \"\"\"\n",
        "      categorical train set은 (미니배치 16, 컬럼 50)의 형태이고, 각 컬럼 별로 뽑아내고 (16,) unsqueeze하면 (16,1) 형식 50개가 된다\n",
        "      각 컬럼 별로 n개의 distinct value가 있다고 할 때에, nn.Embedding 함수는 (n,32) 형식의 Lookup table을 만들고, 들어오는 입력에 따라 k번째에 해당하는 32차원 벡터를 출력으로 내놓게 된다.\n",
        "      최종적으로는 (16,1,32) 형태의 3차원 벡터가 출력된다. 이를 torch.cat(dim=1)하게 되면, (16,50,32)가 각 미니배치별로 생성된다.\n",
        "\n",
        "      Numerical train set을 임베딩할 때에 .unsqueeze가 2번 사용되고 있지만, 첫 번째 unsqueeze는 (16,) -> (16,1)로 변환시키고, 이 벡터가 nn.Linear 함수를 통과하면서 1은 사라지고, (16,32)의 결과물만 남게되고,\n",
        "      두 번째 .unsqueeze를 통해 (16,1,32) 형태가 되고, torch.cat을 통해 (16,45,32)가 되고, cat_emb와 concat이 가능하게 된다.\n",
        "      \"\"\"\n",
        "      cat_emb = torch.cat([self.embeddings[i](x_cat[:,i]).unsqueeze(1) for i in range(self.cnt_cat_features)], dim=1)\n",
        "      num_emb = torch.cat([self.num_embeddings[i](x_num[:,i].unsqueeze(1)).unsqueeze(1) for i in range(self.cnt_num_features)], dim=1)\n",
        "      x = torch.cat([cat_emb,num_emb],dim=1)\n",
        "\n",
        "      x = self.transformer(x)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "DqFz8iasdSqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "hnggE4ctctQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S86GVKw0crTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLAjdzcucoP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r2hFEi_ObYvc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUTTxo5Vbxhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWaWEF9HbX7b"
      },
      "outputs": [],
      "source": []
    }
  ]
}