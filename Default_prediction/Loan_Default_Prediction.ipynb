{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjGGZOMTnxXYJU1Y0CRuj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WB-Jang/ML-notebooks/blob/main/Default_prediction/Loan_Default_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 은행 여신 계좌의 Default를 예측하기 위한 Deep Learning Development\n",
        "(1) Data Set\n",
        "- FY 2024 all seg loan acct\n",
        "- Each month-end snapshot\n",
        "- All columns are divided into 2 group : Numerical, Categorical\n",
        "-\n",
        "- Only from 68 columns  \n",
        "## Pre-training\n",
        "- Masked Auto-Encoder ver\n",
        "- Contrastive Learning ver"
      ],
      "metadata": {
        "id": "o6N9t31rbzxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuarcy_score, roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    # Transformer Encdoer\n",
        "    def __init__(self, cnt_cat_features, cnt_num_features, cat_max_dict, d_model=32, nhead=4, num_layers=6, dim_feedforward=64, dropout_rate=0.3):\n",
        "      super().__init__()\n",
        "      self.d_model = d_model\n",
        "      self.cnt_cat_features = cnt_cat_features\n",
        "      self.cnt_num_features = cnt_num_features\n",
        "    # 범주형 변수 임베딩\n",
        "      self.embeddings = nn.ModuleList([\n",
        "          nn.Embedding(cat_mat_dict[i],d_model) for i in range(cnt_cat_features)\n",
        "      ])\n",
        "    # 수치형 변수 임베딩\n",
        "      self.num_embeddings = nn.ModuleList([\n",
        "          nn.Embedding(1,d_model) for _ in range(cnt_num_features)\n",
        "      ])\n",
        "\n",
        "    # Transformer 인코더 레이어 정의\n",
        "      encoder_layer = nn.TransformerEncoderLayer( # TransformerEncoderLayer에는 self-attention이 기본으로 포함. CrossAttention이 필요하다면, nn.TransformerDecoderLayer 사용\n",
        "          d_model=d_model\n",
        "          , nhead=nhead\n",
        "          , dim_feedforward=dim_feedforward\n",
        "          , dropout=dropout_rate\n",
        "          , batch_first=True # batch_first 옵션은 입력 차원을 (Sequential_length, batch_size, embedding_dim) -> (batch_size, Sequential_length, embedding_dim)로 변경. 이렇게 변경하면 각 data point 별로 하나의 tabular data 형식을 가짐\n",
        "          , norm_first=True # norm_first 옵션은 layer_norm -> residual_connection 순서로 진행한다는 의미. 직관적으로 생각했을 때에는, Residual Connection -> Layer norm을 하게 되면, Residual의 의미가 반감되는 느낌.\n",
        "      )\n",
        "      self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x_cat, x_num):\n",
        ""
      ],
      "metadata": {
        "id": "DqFz8iasdSqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "hnggE4ctctQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S86GVKw0crTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLAjdzcucoP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r2hFEi_ObYvc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUTTxo5Vbxhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWaWEF9HbX7b"
      },
      "outputs": [],
      "source": []
    }
  ]
}